# DeepMIR
Teaching material for the course (CommE5070) "Deep Learning for Music Analysis and Generation" I taught at National Taiwan University (2023 Fall).
https://affige.github.io/teaching.html

Lecture: Yi-Hsuan Yang (https://affige.github.io/; affige@gmail.com)

“Music Information Research” (MIR) is an interdisciplinary research field that concerns with the analysis, retrieval, processing, and generation of musical content or information. Researchers involved in MIR may have a background in signal processing, machine learning, information retrieval, human-computer interaction, musicology, psychoacoustics, psychology, or some combination of these.

In this course, we are mainly interested in the application of machine learning, in particular deep learning, to address music related problems. Specifically, the course is divided to two parts: analysis and generation.

The first part is about the **analysis** of musical audio signals, covering topics such as feature extraction and representation learning for musical audio, music audio classification, melody extraction, automatic music transcription, and musical source separation.

The second part is about the **generation** of musical material, including symbolic-domain MIDI or tablatures, and audio-domain music signals such as singing voices and instrumental music. This would involve deep generative models such as generative adversarial networks (GANs), variational autoencoders (VAE), Transformers, and diffusion models. 


# Syllabus
* W1. Introduction to the course ([slides1](https://github.com/affige/DeepMIR/blob/main/lecture01_intro_course.pdf), [slides2](https://github.com/affige/DeepMIR/blob/main/lecture01b_intro_MIR.pdf))
* W2. Fundamentals & Music representation ([slides](https://github.com/affige/DeepMIR/blob/main/lecture02_representations.pdf))
* W3. Analysis I (timbre): Automatic music classification and representation learning ([slides](https://github.com/affige/DeepMIR/blob/main/lecture03_timbre.pdf))
* W4. Generation I: Source separation
* W5. Generation II: GAN & Vocoders
* W6. Generation III: Synthesis of notes and loops
* W7. Analysis II (pitch): Music transcription, Melody extraction, and Chord Recognition
* W8. Analysis III (rhythm): Beat/downbeat tracking
* W9. Generation IV: Symbolic MIDI generation
* W10. Generation V: Singing voice generation
* W11. Generation VI: Differentiable DSP models and automatic mixing
* W12. Project pitch
* W13. Generation VII: Symbolic MIDI generation: Advanced Topics
* W14. Generation VIII: Text-to-music generation
* W15. Miscellaneous Topics
* W16. Final project presentation


# License
The slides are licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (https://creativecommons.org/licenses/by-nc-sa/4.0/). By downloading the slides, you agree to this license.

![](license.png)
