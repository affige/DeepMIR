# DeepMIR
Teaching material for the course (CommE5070) "Deep Learning for Music Analysis and Generation" I taught at National Taiwan University ([2023 Fall](https://affige.github.io/teaching_deepmir23.html), [2024 Fall](https://affige.github.io/teaching_deepmir24.html), [2025 Fall](https://affige.github.io/teaching_deepmir25.html)).

Lecturer: Yi-Hsuan Yang (https://affige.github.io/; affige@gmail.com; yhyangtw@ntu.edu.tw)

“Music Information Research” (MIR) is an interdisciplinary research field that concerns with the analysis, retrieval, processing, and generation of musical content or information. Researchers involved in MIR may have a background in signal processing, machine learning, information retrieval, human-computer interaction, musicology, psychoacoustics, psychology, or some combination of these.

In this course, we are mainly interested in the application of machine learning, in particular deep learning, to address music related problems. Specifically, the course is divided to two parts: analysis and generation.

The first part is about the **analysis** of musical audio signals, covering topics such as feature extraction and representation learning for musical audio, music audio classification, melody extraction, automatic music transcription, and musical source separation.

The second part is about the **generation** of musical material, including symbolic-domain MIDI or tablatures, and audio-domain music signals such as singing voices and instrumental music. This would involve deep generative models such as generative adversarial networks (GANs), variational autoencoders (VAE), Transformers, and diffusion models. 

# Syllabus (of year 2025)
* Lecture 1. Introductions ([slides](https://github.com/affige/DeepMIR/blob/main/2025/lecture01_intro.pdf)) & fundamentals of musical audio  ([slides](https://github.com/affige/DeepMIR/blob/main/2025/lecture01b_fundamentals_audio.pdf))
* Lecture 2. Music classification & music foundation models ([slides](https://github.com/affige/DeepMIR/blob/main/2025/lecture02_classification.pdf))
* Lecture 3. Audio codec models & audio language models & audio captioning
* Lecture 4. Audio effect modeling
* Lecture 5. Transformer-based music generation
* Lecture 6. Diffusion-based music generation
* Lecture 7. Singing voice generation & song generation
*	Lecture 8. Differentiable DSP models and automatic mixing
* Lecture 9. Fundamentals of symbolic music & symbolic MIDI generation
*	Lecture 10. Advanced symbolic MIDI generation
*	Lecture 11. Cover generation & MIDI-to-audio generation
*	Lecture 12. Miscellaneous topics
*	Lecture 13. Miscellaneous topics


# Syllabus (of year 2024)
* Lecture 1. Introduction to the course ([slides](https://github.com/affige/DeepMIR/blob/main/2024/lecture01_intro_course.pdf))
* Lecture 2. Fundamentals of musical audio ([slides](https://github.com/affige/DeepMIR/blob/main/2024/lecture02_fundamentals_audio.pdf))
* Lecture 3. Music classification and transcription ([slides](https://github.com/affige/DeepMIR/blob/main/2024/lecture03_classification_transcription.pdf))
* Lecture 4. Source separation ([slides](https://github.com/affige/DeepMIR/blob/main/2024/lecture04_separation.pdf))
* Lecture 5. GAN & Vocoders ([slides](https://github.com/affige/DeepMIR/blob/main/2024/lecture05_vocoders.pdf))
* Lecture 6. Fundamentals of symbolic music ([slides](https://github.com/affige/DeepMIR/blob/main/2024/lecture06_fundamentals_symbolic.pdf))
* Lecture 7. Symbolic MIDI generation ([slides](https://github.com/affige/DeepMIR/blob/main/2024/lecture07_midi_generation.pdf))
*	Lecture 8. Synthesis and timbre transfer ([slides](https://github.com/affige/DeepMIR/blob/main/2024/lecture08_synthesis.pdf))
* Lecture 9. Differentiable DSP models and automatic mixing ([slides1](https://github.com/affige/DeepMIR/blob/main/2024/lecture09_DDSP.pdf), [slides2](https://github.com/affige/DeepMIR/blob/main/2024/lecture09b_guitar_yuhua.pdf), [slides3](https://github.com/affige/DeepMIR/blob/main/2024/lecture09c_mixing_yentung.pdf))
*	Lecture 10. Singing voice generation ([slides](https://github.com/affige/DeepMIR/blob/main/2024/lecture10_singing_generation.pdf))
*	Lecture 11. Text-to-music generation ([slides](https://github.com/affige/DeepMIR/blob/main/2024/lecture11_text-to-music.pdf))
*	Lecture 12. Miscellaneous Topics (emotion/structure/alignment/rhythm) ([slides](https://github.com/affige/DeepMIR/blob/main/2024/lecture12_miscellaneous.pdf))


# Syllabus (of year 2023)
* Lecture 1. Introduction to the course ([slides1](https://github.com/affige/DeepMIR/blob/main/2023/lecture01_intro_course.pdf), [slides2](https://github.com/affige/DeepMIR/blob/main/2023/lecture01b_intro_MIR.pdf))
* Lecture 2. Fundamentals & Music representation ([slides](https://github.com/affige/DeepMIR/blob/main/2023/lecture02_representations.pdf))
* Lecture 3. Analysis I (timbre): Automatic music classification and representation learning ([slides](https://github.com/affige/DeepMIR/blob/main/2023/lecture03_timbre.pdf))
* Lecture 4. Generation I: Source separation ([slides](https://github.com/affige/DeepMIR/blob/main/2023/lecture04_separation.pdf))
* Lecture 5. Generation II: GAN & Vocoders ([slides](https://github.com/affige/DeepMIR/blob/main/2023/lecture05_vocoders.pdf))
* Lecture 6. Generation III: Synthesis of notes and loops ([slides](https://github.com/affige/DeepMIR/blob/main/2023/lecture06_synthesis.pdf))
* Lecture 7. Analysis II (pitch): Music transcription, Melody extraction, and Chord Recognition ([slides1](https://github.com/affige/DeepMIR/blob/main/2023/lecture07_pitch.pdf), [slides2](https://github.com/leo-so/AMT_talk))
*	Lecture 8. Generation IV: Symbolic MIDI generation ([slides](https://github.com/affige/DeepMIR/blob/main/2023/lecture08_midi_generation.pdf))
*	Lecture 9. Generation V: Symbolic MIDI generation: Advanced topic on music structure ([slides](https://github.com/affige/DeepMIR/blob/main/2023/lecture09_midi_generation_2.pdf))
*	Lecture 10. Generation VI: Singing voice generation ([slides](https://github.com/affige/DeepMIR/blob/main/2023/lecture10_singing_generation.pdf))
* Lecture 11. Generation VII: Text-to-music generation ([slides](https://github.com/affige/DeepMIR/blob/main/2023/lecture11_text-to-music.pdf))
*	Lecture 12. Generation VIII: Differentiable DSP models and automatic mixing ([slides](https://github.com/affige/DeepMIR/blob/main/2023/lecture12_DDSP_mixing.pdf))
*	Lecture 13. Analysis III (rhythm) ([slides](https://github.com/affige/DeepMIR/blob/main/2023/lecture13_rhythm.pdf))



# License
The slides are licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (https://creativecommons.org/licenses/by-nc-sa/4.0/). By downloading the slides, you agree to this license.

![](license.png)
